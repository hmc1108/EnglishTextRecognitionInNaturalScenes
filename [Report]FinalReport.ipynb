{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ENGLISH TEXT RECOGNITION IN NATURAL SCENCES</span>\n",
    "\n",
    "###   *1412060 - Huỳnh Minh Chương*\n",
    "###   *1412165 - Nguyễn Trung Hiếu*\n",
    "________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________\n",
    "________________________________________________________________________________________________________________________________\n",
    "\n",
    "## <span style=\"color:red\">PHẦN GIỚI THIỆU</span>\n",
    "\n",
    "### <span style=\"color:blue\">1. Giới thiệu:</span>\n",
    "\n",
    "- **Mục đích nghiên cứu:** nghiên cứu về việc sử dụng máy học và xử lý ảnh để nhận dạng ký tự trong các hình ảnh thiên nhiên nhằm trích xuất chính xác nội dung văn bản có trong hình ảnh để có thể hỗ trợ dịch nội dung văn bản sang một ngôn ngữ khác.\n",
    "\n",
    "\n",
    "- **Đối tượng và phạm vi nghiên cứu :** Trong lĩnh vực OCR - Optical Character Recognition (nhận dạng ký tự) đối tượng nghiên cứu chủ yếu ở đây chính là văn bản với phạm vi là nhận dạng được văn bản trong hình ảnh chứa cảnh thiên nhiên.\n",
    "\n",
    "## <span style=\"color:red\">PHẦN NỘI DUNG</span>\n",
    "\n",
    "### <span style=\"color:blue\">2. Hiện trạng vấn đề và tổng quan các nghiên cứu trước:</span>\n",
    "\n",
    "- Tầm quan trọng của xử lý hình ảnh đã tăng lên rất nhiều trong những năm qua. Với sự phát triển về phần cứng của các thiết bị di động cũng như sự gia tăng nhu cầu ứng dụng các thiết bị di động vào tất cả các hoạt động cuộc sống thường ngày. Các tựa game và phần mềm tương tác trực tiếp với môi trường ngày càng gây sốt với người dùng như PokemonGo, nhận diện và bảo mật bằng khuôn mặt,..... \n",
    "\n",
    "\n",
    "- Máy học rõ ràng đóng một vai trò rất quan trọng trong lĩnh vực này, phát hiện văn bản tự động và nhận dạng ký tự chỉ là một ví dụ. Người ta có thể trích dẫn ứng dụng phức tạp khác như xác định các loài động vật, thực vật, phát hiện con người hay, nói chung, khai thác bất kỳ loại thông tin nào.\n",
    "\n",
    "\n",
    "- Lĩnh vực OCR đã được nghiên cứu rất sâu trong những thập kỷ qua. Trên thực tế, hiện nay, vấn đề nhận dạng ký tự từ các tài liệu nền đen và trắng đã được là giải quyết. Vấn đề này khá phổ biến khi cần quét ảnh các tài liệu bằng cách sử dụng một số phần mềm để chuyển đổi nó thành một tập tin văn bản. Ngoài ra còn có rất nhiều các công cụ mã nguồn mở trên mạng, chẳng hạn như Tesseract OCR - có khả năng đọc và phát hiện lên đến 60 ngôn ngữ. Những trường hợp kể trên là những trường hợp dễ, các hình ảnh có độ tương phản rất tốt, đơn nền, không có vấn đề khó khăn trong việc phát hiện các đường viền, đường bao mà chỉ gặp vấn đề do độ sáng của ảnh.\n",
    "\n",
    "\n",
    "- Vấn đề này lại rất khác khi chúng ta thực hiện quét kí tự trên những ảnh cảnh thiên nhiên, ví dụ một bức ảnh chụp bởi một người dùng twitter, facebook và sau đó được đăng trên các nền tảng xã hội. Trong trường hợp này, vấn đề chưa được giải quyết vì gặp rất nhiều vấn đề lớn trong việc xử lý ảnh. Một trong những công cụ lớn và đi dầu trong lĩnh vực này là Google Translator có khả năng phát hiện và dịch văn bản từ hình ảnh, nhưng dù sao kết quả không hoàn toàn hài lòng và phụ thuộc vào chất lượng của hình ảnh và trên môi trường điều kiện (đêm / ngày, ánh sáng / độ bóng).\n",
    "\n",
    "\n",
    "- Chính vì thể việc nghiên cứu vấn đề nhận dạng văn bản trong ảnh cảnh thiên nhiên cũng rất quan trọng trong thời kỳ hiện nay. Bằng sự kết hợp của một số thư viện trong Python như Pandas, Scikit-Learn, Numpy, Skimage... Tuy không đạt được độ chính xác tuyệt đối nhưng vấn đề này đã được giải quyết theo một hướng đúng và tương lai sẽ được cải tiến và giải quyết với độ chính xác tuyệt đối với cách giải quyết theo hướng giải quyết này.\n",
    "*******************************************************************************************************************************\n",
    "### <span style=\"color:blue\">3. Phát biểu giả thiết hay giải pháp:</span>\n",
    "\n",
    "- Để giải quyết được bài toán trước tiên có thể chia bài toán gồm 4 nội dụng cần thực hiện:\n",
    "    + Bước 1: Quá trình tiền xử lý hình ảnh và nhận diện các đối tượng.\n",
    "    + Bước 2: Nhận diện các đối tượng có thể là ký tự.\n",
    "    + Bước 3: Nhận diện và gắn nhãn các ký tự đã phát hiện.\n",
    "    + Bước 4: Gắn các ký tự vào đúng vị trí trên ảnh.\n",
    "\n",
    "#### 3.1. Các cơ sở lý thuyết:\n",
    "- Dựa vào các phương pháp giảm nhiễu cũng như tăng tính tương phản trong xử lý ảnh để xử lý ảnh đầu vào.\n",
    "- Dựa vào phương pháp rút trích đặc trưng, phương pháp phân lớp trong máy học.\n",
    "\n",
    "#### 3.2 Các thuật toán:\n",
    "- **Giảm nhiễu(Denoising)**: Việc này được thực hiện với phương pháp giảm nhiễu biến đổi hoàn toàn [Total variation denoising](https://en.wikipedia.org/wiki/Total_variation_denoising) đây là một trong những phương pháp giảm nhiễu tốt nhất trong xử lý ảnh. Việc giảm nhiễu với mục đích giảm nhiều nhất có thể việc tách rời các gradient tuyệt đối của hình ảnh. Gradient của hình ảnh được hiểu đơn giản chính là sự thay đổi hướng của cường độ hoặc màu sắc trong chính hình ảnh.  \n",
    "- **Tăng tính tương phản(Increase contrast)**: Được thực hiện với phương pháp Otsu ([Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method)). Phương pháp sẽ tính toán ngưỡng tối ưu nhất bằng phương pháp tối ưu hóa phương sai giữa hai lớp điểm ảnh (pixels), được phân cách bởi ngưỡng. Và nó sẽ giảm thiểu các sai khác trong mỗi lớp.\n",
    "- **Trích xuất các đặc trưng:** Bước này sẽ tính toán [Histogram of Gradient](http://scikit-image.org/docs/dev/auto_examples/plot_hog.html) (HOG) của ảnh. Kỹ thuật ở đây dựa vào việc ta có thể mô tả thể hiện và hình dáng của các đối tượng trong ảnh bằng sự phân bố cường độ các gradient (gradient là sự thay đổi hướng của cường độ hoặc màu của ảnh). Cách này thường được sử dụng trong việc nhận diện đối tượng vì nó có thể tìm ra các đường bao của hình dáng một cách tương đối dễ dàng. Khi thực hiện xong bước này, ta được một tập các điểm dữ liệu đặc trưng cần thiết cho việc phân loại.  \n",
    "- **Phân loại**: Bước này sử dụng phương pháp [Support Vector Machines with a Linear Kernel](http://scikit-learn.org/stable/modules/svm.html) (SVM)  \n",
    "- **Đánh giá mô hình máy học**: Bước này sử dụng Grid Search Cross Validation của thư viện scikit - learn. Với bộ tham số khác nhau cho thuật toán HOG và SVM, phương pháp này sẽ chạy từng mô hình và đánh giá kết quả bằng cách so sánh kết quả phân lớp với nhãn. Đây là bước quan trọng quyết định độ chính xác của mô hình.  \n",
    "\n",
    "### <span style=\"color:blue\">4. Thực nghiệm và đánh giá giải pháp:  </span>\n",
    "#### 4.1. Tiền xử lý ảnh và nhận diện đối tượng\n",
    "\n",
    "_**Step 1**_: Đầu tiên chúng ta cần dữ liệu đầu vào của bài toán đó là một hình ảnh. Ở đây ví dụ là hình ảnh như sau: \n",
    "\n",
    "![lao](img/lao.jpg)\n",
    "\n",
    "\n",
    "* Đây là hình ảnh chứa văn bản tiếng Anh. Nhiệm vụ đặt ra trước mắt là cần phải load dữ liệu đầu vào và sau đó xử lý hai yếu tố chính là:\n",
    "\n",
    "    _1. Giảm nhiễu(Denoising)_ : Việc này được thực hiện với phương pháp giảm nhiễu biến đổi hoàn toàn [Total variation denoising](https://en.wikipedia.org/wiki/Total_variation_denoising) đây là một trong những phương pháp giảm nhiễu tốt nhất trong xử lý ảnh. Việc giảm nhiễu với mục đích giảm nhiều nhất có thể việc tách rời các gradient tuyệt đối của hình ảnh. Gradient của hình ảnh được hiểu đơn giản chính là sự thay đổi hướng của cường độ hoặc màu sắc trong chính hình ảnh.\n",
    "    \n",
    "    _2. Tăng tính tương phản(Increase contrast)_ : Được thực hiện với phương pháp Otsu ([Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method)). Phương pháp sẽ tính toán ngưỡng tối ưu nhất bằng phương pháp tối ưu hóa phương sai giữa hai lớp điểm ảnh (pixels), được phân cách bởi ngưỡng. Và nó sẽ giảm thiểu các sai khác trong mỗi lớp.\n",
    "    \n",
    "_**Step 2**_: Sau khi chúng ta tiền xử lý ở step 1 tiếp theo là sẽ phát hiện các đối tượng và kết hợp với việc vẽ hình chữ nhật quanh mỗi đối tượng được phát hiện. Với quá trình này từ hình ảnh gốc ta biến đổi ra được hình ảnh sau:\n",
    "\n",
    "![preprocessed1](img/preprocessed1.png)\n",
    "\n",
    "* Như hình trên không phải tất cả các đối tượng được phát hiện đều là văn bản. Sau đó các đối tượng được chuyển đổi sang ảnh xám và sẽ được thay đổi kích thước về 20x20 pixel. Các tọa độ của hình chữ nhật cũng được lưu để tái tạo hình ảnh sau đó. Kết quả của quá trình này được thể hiện ở ảnh sau (100 ảnh ngẫu nhiên các đối tượng):\n",
    "\n",
    "![TOD1](img/TOD1.png)  \n",
    "\n",
    "#### 4.2. Nhận diện đối tượng là ký tự\n",
    "##### a. Định hướng\n",
    "\n",
    "Thách thức đặt ra là làm sao để xác định các đối tượng vừa nhận diẹn được có chứa văn bản để phân loại chúng. Để giải quyết vấn đề này ta cần một tập dữ liệu huấn luyện lý tưởng gồm 50% số hình có chứa văn bản và 50% còn lại không chứa. Để tạo ra tập dữ liệu này ta cần kết hợp 2 tập dữ liệu:  \n",
    "1. 50 000 ảnh được lấy từ 78 903 hình ở tập dữ liệu [74K Chars dataset](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/).Tập này gồm những hình ảnh có văn bản và được dán nhãn là 1\n",
    "2. 50 000 ảnh được lấy từ tập [CIFAR-10 dataset on Kaggle](https://www.kaggle.com/c/cifar-10/data). Những hình ảnh trong tập này không có văn bản và được dán nhãn là 0  \n",
    "  \n",
    "Tập hoàn chỉnh gồm 100 000 ảnh, được dán nhãn đúng và trộn lại theo 1 thứ tự ngẫu nhiên. Do vậy, ta cần một mô hình phân lớp nhị phân.  \n",
    "\n",
    "Mô hình này gồm 2 bước:  \n",
    "1. **Trích xuất các đặc trưng:** Bước này sẽ tính toán [Histogram of Gradient](http://scikit-image.org/docs/dev/auto_examples/plot_hog.html) (HOG) của ảnh. Kỹ thuật ở đây dựa vào việc ta có thể mô tả thể hiện và hình dáng của các đối tượng trong ảnh bằng sự phân bố cường độ các gradient (gradient là sự thay đổi hướng của cường độ hoặc màu của ảnh). Cách này thường được sử dụng trong việc nhận diện đối tượng vì nó có thể tìm ra các đường bao của hình dáng một cách tương đối dễ dàng. Khi thực hiện xong bước này, ta được một tập các điểm dữ liệu đặc trưng cần thiết cho việc phân loại.  \n",
    "2. **Phân loại**: Bước này sử dụng phương pháp [Support Vector Machines with a Linear Kernel](http://scikit-learn.org/stable/modules/svm.html) (SVM)\n",
    "\n",
    "##### b. Thực hiện\n",
    "Nhóm đã xây dựng các lớp sau cho việc train dữ liệu và đánh giá mô hình:\n",
    "1. Lớp **CifarKaggle** dùng cho việc đọc và xử lý dữ liệu không chứa text trong tập **CIFAR**. Dữ liệu được đọc từ file **cifar-cofig.py** - được lưu dạng dictionary. Dictionary gồm các key như sau: \n",
    "     - **'verbose'**: True - ghi các kết quả từng bước ra màn hình, False thì ngược lại  \n",
    "     - **'from_pickle'**: True - đọc file dữ liệu từ pickle_data. False thì load ảnh từ folder và ghi vào file pickle  \n",
    "     - **'pickle_data'**: File pickle lưu dữ liệu ảnh đã load, tiết kiệm thời gian  \n",
    "     - **'folder'**: Folder chứa ảnh cần load lên, cũng là thư mục chứa pickle_data   \n",
    "     - **'img_size'**: Kích thước ảnh cần resize  \n",
    "    \n",
    "2. Lớp **OcrData** dùng cho việc tạo tập dữ liệu 100000 ảnh, train dữ liệu và đánh giá các mô hình. Có các hàm chính sau:  \n",
    "  - **merge_with_cifar**: lấy dữ liệu 50000 ảnh chứa kí tự từ file **text-config.py** (tập 74K Chars) trộn với 50000 ảnh không chứa kí tự từ file **cifar-config.py** (tập CIFAR) để tạo thành tập train  \n",
    "  - **perform_grid_search_cv**: Dùng Grid Search Cross Validation để đánh giá các tham số khác nhau cho thuật toán SVM + HOG để tìm ra được bộ tham số có score tốt nhất.  \n",
    "  - **generate_best_hog_model**: Khi đã có bộ tham số thì ta dựng lại mô hình trên toàn bộ tập train 100000  \n",
    "  - **evaluate**: Đánh giá và vẽ biểu đồ biểu thị độ chính xác của mô hình trên toàn bộ tập train 100000    \n",
    "  \n",
    "  File **text-cofig.py** và **ocr-config.py** đều có chung cấu trúc như sau:    \n",
    "  - **'from_pickle', 'pickle_data', 'folder_data', 'verbose', 'img_size'**: tương tự như file  **cifar-cofig.py**  \n",
    "  - **'folder_labels'**: Thư mục lưu nhãn của tập dữ liệu (nếu không load từ file pickle)  \n",
    "  - **'limit'**: giới hạn số ảnh cần load  \n",
    "  - **'automatic_split'**: True - tự động chia tập dữ liệu thành train và test, False - ngược lại  \n",
    "  - **'plot_evaluation'**: True - biểu diễn dữ liệu, False - ngược lại  \n",
    "  - **'percentage_of_test_set'**: Tỉ lệ dữ liệu test - để chia dữ liệu \n",
    "  \n",
    "Bổ sung thêm phương thức **select_text_among_candidates** cho lớp **ImageData**, để lọc các đối tượng chứa text dựa vào mô hình đã dựng được  \n",
    "##### c. Kết quả\n",
    "Sau khi đánh giá các mô hình khác nhau bằng phương pháp **Grid Search Cross Validation**, ta được kết quả như sau:  \n",
    "Sau khi chạy 324 bộ tham số cho mô hình SVM-HOG, mỗi bộ tham số chạy 3 lần, ta được tham số có score validation cao nhất là    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mean: 0.87501, std: 0.00128, params: {'hog__cells_per_block': (4, 4), 'hog__orientations': 5, 'clf__C': 2, 'hog__pixels_per_cell': (2, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi dựng lại mô hình trên toàn bộ tập 100000 ảnh, ta được kết quả như sau về độ chính xác:  \n",
    "![generate_best_hog_model](img/generate_best_hog_model.jpg)  \n",
    "Sau khi đánh giá mô hình, ta được kết quả như sau:  \n",
    "![evaluate](img/evaluate.jpg)  \n",
    "Biểu đồ confusion_matrix biểu diễn độ chính xác của mô hình:  \n",
    "![figure](img/figure.png)  \n",
    "  \n",
    "Kết quả sau khi lọc các đối tượng chứa text, lọc được 66/203 đối tượng có chứa text:  \n",
    "![select_text](img/select_text.jpg)  \n",
    "Kết quả lọc được:  \n",
    "![text_objects](img/text_objects.jpg)  \n",
    "#### 4.3. Nhận diện và gắn nhãn các ký tự đã phát hiện\n",
    "\n",
    "- Ở giai đoạn này là quá trình phân lớp các ký tự đơn dựa vào các dữ liệu đã được training.\n",
    "\n",
    "- Trong trường hợp này bộ dữ liệu gồm có 78.903 hình ảnh có sẵn trong [74K Chars dataset](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/). Chúng ta sẽ phải xử lý phân loại nhị phân nữa là trong trường hợp này, số lượng các lớp học là 36:\n",
    "    + Số nguyên [0-9] :  10 lớp\n",
    "    + Chữ thường của bảng chữ cái tiếng Anh [a-z]: 26 lớp\n",
    "- Bước này chỉ gồm nạp dữ liệu OCR và dựng mô hình dựa trên tập data, nhãn và tham số đã đánh giá ở phần Text Detection sử dụng phương pháp rút trích đặc trưng [Histogram of Gradient](http://scikit-image.org/docs/dev/auto_examples/plot_hog.html) (HOG) của ảnh kết hợp với phương pháp phân loại (SVM) [Support Vector Machines with a Linear Kernel](http://scikit-learn.org/stable/modules/svm.html).\n",
    "- Kết quả thu được là :\n",
    "![SCR2](img/SCR2.png)\n",
    "\n",
    "#### 4.4. Gắn các ký tự vào đúng vị trí trên ảnh  \n",
    "Ở phần cuối này, chương trình sẽ sắp xếp các nhãn kí tự đã xác định được vào đúng vị trí của trên ảnh. \n",
    "Kết quả thu được:\n",
    "![text_reconstruction](img/text_reconstruction.png)  \n",
    "#### 4.5. Đánh giá phương pháp  \n",
    "Dựa vào kết quả thu được, ta nhận thấy rằng phương pháp này chưa thực sự chính xác hoàn toàn, còn rất nhiều ký tự không nhận dạng được hoặc nhận dạng sai thành ký tự khác hoặc rất nhiều đối tượng không phải là ký tự nhưng được nhận diện là ký tự. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color:red\">PHẦN KẾT LUẬN</span>\n",
    "\n",
    "### <span style=\"color:blue\">5. Kết luận:</span>  \n",
    "#### 5.1 Tóm tắt nghiên cứu\n",
    "- Phương pháp xác định ký tự có trong ảnh cảnh thiên nhiên sử dụng kết hợp các thuật toán xử lý ảnh **Total Variant Denoising, Otsu** và sự kết hợp giữa phương pháp trích xuất đặc trưng **HOG** và phương pháp phân lớp **SVM** cũng như phương pháp đánh giá mô hình **Grid Search Cross Validation**  \n",
    "- Kết quả nhận diện kí tự trong các bức ảnh chưa hoàn toàn tốt, chỉ nhận diện được tương đối các ký tự trong ảnh có sự phân biệt rõ ràng với nền. Nguyên nhân có thể là do việc lựa chọn tham số và bộ dữ liệu huấn luyện chưa thực sự tốt.  \n",
    "\n",
    "#### 5.2 Cải tiến\n",
    "- Tạo ra bộ dữ liệu huấn luyện đa dạng hơn để chọn lựa ra bộ tham số tốt hơn.  \n",
    "- Sử dụng các thuật toán autocorrect để xây dựng lại các từ có trong bức ảnh để cho phương pháp này có tính thực tiễn cao hơn.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
